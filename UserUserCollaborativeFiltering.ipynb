{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityMetric:\n",
    "\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarity(SimilarityMetric):\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        u = np.nan_to_num(u, nan=0)\n",
    "        v = np.nan_to_num(v, nan=0)\n",
    "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v) + 1e-9)\n",
    "\n",
    "class PCCSimilarity(SimilarityMetric):\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        return self.__pearson_correlation(u, v)\n",
    "    \n",
    "    def __pearson_correlation(self, user1_ratings, user2_ratings):\n",
    "\n",
    "        x_masked = ma.masked_invalid(user1_ratings)\n",
    "        y_masked = ma.masked_invalid(user2_ratings)\n",
    "\n",
    "        # Create a mask where both x_masked and y_masked are null\n",
    "        combined_mask = ~x_masked.mask & ~y_masked.mask\n",
    "\n",
    "        # Find the indices where both x_masked and y_masked are null\n",
    "        non_null_indices = np.where(combined_mask)\n",
    "                \n",
    "        if len(non_null_indices) < 2:  # Require at least 2 common items for correlation\n",
    "            return 0\n",
    "        \n",
    "        correlation_matrix = ma.corrcoef(x_masked, y_masked)\n",
    "        correlation = correlation_matrix[0,1]\n",
    "\n",
    "        return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        \"\"\"\n",
    "        Initialize CollaborativeFiltering object with user-item rating data.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing user-item ratings\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.similarity_matrix = None\n",
    "        self.metric = metric\n",
    "    \n",
    "    def calculate_similarity_matrix(self):\n",
    "        pass\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        pass\n",
    "\n",
    "    def train_test_split(self, test_size = 0.2):\n",
    "        \"\"\"\n",
    "        Split the data into training and test sets.\n",
    "        \n",
    "        Parameters:\n",
    "        - test_size: Fraction of the data to be used for testing\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # for reproducibility\n",
    "        mask = np.random.rand(len(self.data)) < 1 - test_size\n",
    "        self.train_data = self.data[mask]\n",
    "        self.test_data = self.data[~mask]\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the Collaborative Filtering model on the test set.\n",
    "\n",
    "        Returns:\n",
    "        - Mean squared error (MSE) of the predictions\n",
    "        \"\"\"\n",
    "\n",
    "        mse_sum = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for user_id in self.test_data.index:\n",
    "            user_test_ratings = self.test_data.loc[user_id]\n",
    "            user_predicted_ratings = self.predict_ratings(user_id)\n",
    "            for movie_id, actual_rating in user_test_ratings.items():\n",
    "                predicted_rating = user_predicted_ratings.loc[movie_id, 'PredictedRating']\n",
    "                if not pd.isnull(predicted_rating):\n",
    "                    total_predictions += 1\n",
    "                    mse_sum += (actual_rating - predicted_rating) ** 2\n",
    "\n",
    "        mse = mse_sum / total_predictions\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringItemItem(CollaborativeFiltering):\n",
    "\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        super().__init__(data, metric)\n",
    "    \n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \n",
    "        # user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "        \n",
    "        n_movies = self.data.shape[1]\n",
    "        similarity_matrix = np.zeros((n_movies, n_movies))\n",
    "        for i in range(n_movies):\n",
    "            for j in range(i+1):\n",
    "                temp = self.metric.calculateSimilarity(self.data.iloc[:, i], self.data.iloc[:, j])\n",
    "                similarity_matrix[i, j] = temp\n",
    "                similarity_matrix[j, i] = temp\n",
    "\n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=self.data.columns, columns=self.data.columns)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for items for a given user.\n",
    "\n",
    "        Parameters:\n",
    "        - user_id: ID of the user for whom to predict ratings\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame containing predicted ratings for each item\n",
    "        \"\"\"\n",
    "\n",
    "        user_ratings = self.data.loc[user_id]\n",
    "        predicted_ratings = pd.DataFrame(index=self.data.columns, columns=['PredictedRating'])\n",
    "\n",
    "        for movie_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "\n",
    "            for other_movie_id in predicted_ratings.index:\n",
    "                if (other_movie_id != movie_id):\n",
    "                    similarity = self.similarity_matrix.loc[movie_id, other_movie_id]\n",
    "                    other_movie_rating = user_ratings[other_movie_id]\n",
    "\n",
    "                    if not np.isnan(other_movie_rating):\n",
    "                        numerator += similarity * other_movie_rating\n",
    "                        denominator += abs(similarity)\n",
    "            \n",
    "            predicted_ratings.loc[movie_id, 'PredictedRating'] = numerator / (denominator + 1e-9)\n",
    "            \n",
    "        return predicted_ratings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringUserUser(CollaborativeFiltering):\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        \n",
    "        super().__init__(data, metric)\n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \n",
    "        # user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "\n",
    "        n_users = self.data.shape[0]\n",
    "        similarity_matrix = np.zeros((n_users, n_users))\n",
    "        for i in range(n_users):\n",
    "            for j in range(i+1):\n",
    "                temp = self.metric.calculateSimilarity(self.data.iloc[i, :], self.data.iloc[j, :])\n",
    "                similarity_matrix[i, j] = temp\n",
    "                similarity_matrix[j, i] = temp\n",
    "                \n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=self.data.index, columns=self.data.index)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for items for a given user.\n",
    "\n",
    "        Parameters:\n",
    "        - user_id: ID of the user for whom to predict ratings\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame containing predicted ratings for each item\n",
    "        \"\"\"\n",
    "\n",
    "        predicted_ratings = pd.DataFrame(index=self.data.columns, columns=['PredictedRating'])\n",
    "\n",
    "        for movie_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "\n",
    "            for other_user_id in self.data.index:\n",
    "                other_user_rating = self.data.loc[other_user_id, movie_id]\n",
    "                similarity = self.similarity_matrix.loc[user_id , other_user_id]\n",
    "\n",
    "                if not pd.isnull(other_user_rating):\n",
    "                    numerator += similarity * (other_user_rating)\n",
    "                    denominator += abs(similarity)\n",
    "\n",
    "            predicted_ratings.loc[movie_id, 'PredictedRating'] = numerator / (denominator + 1e-9) \n",
    "            \n",
    "        return predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_222198/103287248.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv(\"EncodedCombined.csv\")\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"EncodedCombined.csv\")\n",
    "\n",
    "user_item_matrix = data.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "user_item_matrix_new = user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = CosineSimilarity()\n",
    "# # Create CollaborativeFiltering instance\n",
    "# cf = CollaborativeFilteringItemItem(user_item_matrix_new, metric)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# cf.train_test_split(test_size=0.2)\n",
    "# cf.calculate_similarity_matrix()\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = cf.evaluate()\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_df = cf.predict_ratings(2)\n",
    "# print(prediction_df.sort_values(by=['PredictedRating']).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = PCCSimilarity()\n",
    "# cf = CollaborativeFilteringItemItem(user_item_matrix_new, metric)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# cf.train_test_split(test_size=0.2)\n",
    "# cf.calculate_similarity_matrix()\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = cf.evaluate()\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_df = cf.predict_ratings(2)\n",
    "# print(prediction_df.sort_values(by=['PredictedRating']).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = CosineSimilarity()\n",
    "# Create CollaborativeFiltering instance\n",
    "cf = CollaborativeFilteringUserUser(user_item_matrix_new, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "cf.calculate_similarity_matrix()\n",
    "\n",
    "# Evaluate the model\n",
    "# mse = cf.evaluate()\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PredictedRating\n",
      "MovieID                \n",
      "3382           4.999999\n",
      "1830                5.0\n",
      "2480                5.0\n",
      "3656                5.0\n",
      "989                 5.0\n",
      "3881                5.0\n",
      "3607                5.0\n",
      "3172                5.0\n",
      "3233                5.0\n",
      "787                 5.0\n"
     ]
    }
   ],
   "source": [
    "prediction_df = cf.predict_ratings(2)\n",
    "print(prediction_df.sort_values(by=['PredictedRating']).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PCCSimilarity()\n",
    "cf = CollaborativeFilteringUserUser(user_item_matrix_new, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "cf.calculate_similarity_matrix()\n",
    "\n",
    "# Evaluate the model\n",
    "# mse = cf.evaluate()\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = cf.predict_ratings(2)\n",
    "print(prediction_df.sort_values(by=['PredictedRating']).tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
