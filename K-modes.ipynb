{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KModes:\n",
    "    def __init__(self, k, max_iter=100):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def initialize_centroids(self, data):\n",
    "        n_samples, n_features = data.shape\n",
    "        centroids = np.zeros((self.k, n_features), dtype=object)  # Initialize centroids array with dtype=object\n",
    "\n",
    "        for i in range(self.k):\n",
    "            centroid = []\n",
    "            for j in range(n_features):\n",
    "                unique_values = np.unique(data.iloc[:, j].astype(str))  # Convert column to string type\n",
    "                centroid.append(np.random.choice(unique_values))\n",
    "            centroids[i] = centroid\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, data, centroids):\n",
    "        # Distance is a 2_D array that will contain a row for each of the data point and then array for each row will contain the distance from the k-modes.\n",
    "        distance = np.zeros((data.shape[0], len(centroids)), dtype=int)\n",
    "        # i and centroid will be used to iterate simultenously using the 2d-array, enumerate function will be used for that .\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            for j in range(data.shape[0]):\n",
    "                # we are iterating through each of the data point and then we compare the number of mismatches and then do the sum.\n",
    "                distance[j, i] = np.sum(data.iloc[j] != centroid)\n",
    "        return distance\n",
    "\n",
    "    def assign_clusters(self, data, centroids):\n",
    "        # calculate the distance for each of the data points.\n",
    "        distances = self.compute_distance(data, centroids)\n",
    "        # Then get the min index of the centroid of each of the data point and then return the array.\n",
    "        clusters = np.argmin(distances, axis=1)\n",
    "        return clusters\n",
    "\n",
    "    def update_centroids(self, data, clusters):\n",
    "        centroids = []\n",
    "        print(self.k)\n",
    "        # used for storing the updates centroids.\n",
    "        for cluster_index in range(self.k):\n",
    "            # cluster_index is used to access the individual clusters\n",
    "            # we then filter out the data points and extract the points only belonging to that cluster.\n",
    "            cluster_data = data[clusters == cluster_index]\n",
    "            centroid = []\n",
    "            # we will iterate through the columns of the filtered cluster and then get the mode of each of the feature and \n",
    "            # then add that as the feature of the centroid and then return the centroid.\n",
    "            for feature_column in cluster_data.columns:\n",
    "                mode = cluster_data[feature_column].mode()[0]\n",
    "                centroid.append(mode)\n",
    "            centroids.append(centroid)\n",
    "        return np.array(centroids)\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "        # this is basically doing the iterations to find the best fit and then stopping if the clusters don't change.\n",
    "        for _ in range(self.max_iter):\n",
    "            old_centroids = self.centroids.copy()\n",
    "            clusters = self.assign_clusters(data, self.centroids)\n",
    "            self.centroids = self.update_centroids(data, clusters)\n",
    "            if np.array_equal(old_centroids, self.centroids):\n",
    "                break\n",
    "        self.clusters = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0 MovieID Rating Action Adventure Animation Children's Comedy  \\\n",
      "1          0.0    1193      5      0         0         0          0      0   \n",
      "2          1.0     661      3      0         0         1          1      0   \n",
      "3          2.0     914      3      0         0         0          0      0   \n",
      "4          3.0    3408      4      0         0         0          0      0   \n",
      "5          4.0    2355      5      0         0         1          1      1   \n",
      "..         ...     ...    ...    ...       ...       ...        ...    ...   \n",
      "95        94.0    1293      5      0         0         0          0      0   \n",
      "96        95.0    1188      4      0         0         0          0      1   \n",
      "97        96.0    3255      4      0         0         0          0      1   \n",
      "98        97.0    3256      2      1         0         0          0      0   \n",
      "99        98.0    3257      3      1         0         0          0      0   \n",
      "\n",
      "   Crime Documentary  ... Horror Musical Mystery Romance Sci-Fi Thriller War  \\\n",
      "1      0           0  ...      0       0       0       0      0        0   0   \n",
      "2      0           0  ...      0       1       0       0      0        0   0   \n",
      "3      0           0  ...      0       1       0       1      0        0   0   \n",
      "4      0           0  ...      0       0       0       0      0        0   0   \n",
      "5      0           0  ...      0       0       0       0      0        0   0   \n",
      "..   ...         ...  ...    ...     ...     ...     ...    ...      ...  ..   \n",
      "95     0           0  ...      0       0       0       0      0        0   0   \n",
      "96     0           0  ...      0       0       0       1      0        0   0   \n",
      "97     0           0  ...      0       0       0       0      0        0   0   \n",
      "98     0           0  ...      0       0       0       0      0        1   0   \n",
      "99     0           0  ...      0       0       0       1      0        1   0   \n",
      "\n",
      "   Western Age Zip-code  \n",
      "1        0   1    48067  \n",
      "2        0   1    48067  \n",
      "3        0   1    48067  \n",
      "4        0   1    48067  \n",
      "5        0   1    48067  \n",
      "..     ...  ..      ...  \n",
      "95       0  56    70072  \n",
      "96       0  56    70072  \n",
      "97       0  56    70072  \n",
      "98       0  56    70072  \n",
      "99       0  56    70072  \n",
      "\n",
      "[99 rows x 23 columns]\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m k_modes \u001b[38;5;241m=\u001b[39m KModes(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Specify the number of clusters (k)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 5. Fit the model using the train data\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mk_modes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 6. Predict clusters for test data\u001b[39;00m\n\u001b[0;32m     18\u001b[0m test_clusters \u001b[38;5;241m=\u001b[39m k_modes\u001b[38;5;241m.\u001b[39massign_clusters(test_data, k_modes\u001b[38;5;241m.\u001b[39mcentroids)\n",
      "Cell \u001b[1;32mIn[11], line 59\u001b[0m, in \u001b[0;36mKModes.fit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     57\u001b[0m old_centroids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     58\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_clusters(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids)\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_centroids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(old_centroids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 48\u001b[0m, in \u001b[0;36mKModes.update_centroids\u001b[1;34m(self, data, clusters)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# we will iterate through the columns of the filtered cluster and then get the mode of each of the feature and \u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# then add that as the feature of the centroid and then return the centroid.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_column \u001b[38;5;129;01min\u001b[39;00m cluster_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 48\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     49\u001b[0m     centroid\u001b[38;5;241m.\u001b[39mappend(mode)\n\u001b[0;32m     50\u001b[0m centroids\u001b[38;5;241m.\u001b[39mappend(centroid)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:1111\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:1227\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Combined.csv\",low_memory=False)\n",
    "data = data.reset_index(drop=True)\n",
    "data=data.iloc[1:100]\n",
    "data=data.drop(columns=[\"Title\",\"UserID\"])\n",
    "\n",
    "print(data)\n",
    "# 2. Preprocess the data if needed\n",
    "\n",
    "# 3. Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)  # Adjust test_size as needed\n",
    "\n",
    "# 4. Instantiate the KModes class\n",
    "k_modes = KModes(k=3)  # Specify the number of clusters (k)\n",
    "# 5. Fit the model using the train data\n",
    "k_modes.fit(train_data)\n",
    "\n",
    "# 6. Predict clusters for test data\n",
    "test_clusters = k_modes.assign_clusters(test_data, k_modes.centroids)\n",
    "\n",
    "# 7. Calculate the Silhouette Score\n",
    "silhouette_avg = silhouette_score(test_data, test_clusters)\n",
    "print(\"Silhouette Score:\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
