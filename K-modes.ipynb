{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinivasan M\\AppData\\Local\\Temp\\ipykernel_24080\\1662815981.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KModes:\n",
    "    def __init__(self, k, max_iter=100):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def initialize_centroids(self, data):\n",
    "        n_samples, n_features = data.shape\n",
    "        # centroids is the two dimensional array that will contain k-rows and n_coloumns(n == number of features)\n",
    "        centroids = np.zeros((self.k, n_features), dtype=object)\n",
    "        # Now iterating through each of the k-centroid\n",
    "        for i in range(self.k):\n",
    "            centroid = []\n",
    "            # above is the array that will contain the features of that particular centroid.\n",
    "            for j in range(n_features):\n",
    "                # we are iterating through the unique values of a particular feature and then randomly assigning one of them to the centroid.\n",
    "                unique_values = np.unique(data.iloc[:, j])\n",
    "                centroid.append(np.random.choice(unique_values))\n",
    "            centroids[i] = centroid\n",
    "        # now centroids will contain info about all the inital centroid(features)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, data, centroids):\n",
    "        # Distance is a 2_D array that will contain a row for each of the data point and then array for each row will contain the distance from the k-modes.\n",
    "        distance = np.zeros((data.shape[0], len(centroids)), dtype=int)\n",
    "        # i and centroid will be used to iterate simultenously using the 2d-array, enumerate function will be used for that .\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            for j in range(data.shape[0]):\n",
    "                # we are iterating through each of the data point and then we compare the number of mismatches and then do the sum.\n",
    "                distance[j, i] = np.sum(data.iloc[j] != centroid)\n",
    "        return distance\n",
    "\n",
    "    def assign_clusters(self, data, centroids):\n",
    "        # calculate the distance for each of the data points.\n",
    "        distances = self.compute_distance(data, centroids)\n",
    "        # Then get the min index of the centroid of each of the data point and then return the array.\n",
    "        clusters = np.argmin(distances, axis=1)\n",
    "        return clusters\n",
    "\n",
    "    def update_centroids(self, data, clusters):\n",
    "        centroids = []\n",
    "        # used for storing the updates centroids.\n",
    "        for cluster_index in range(self.k):\n",
    "            # cluster_index is used to access the individual clusters\n",
    "            # we then filter out the data points and extract the points only belonging to that cluster.\n",
    "            cluster_data = data[clusters == cluster_index]\n",
    "            centroid = []\n",
    "            # we will iterate through the columns of the filtered cluster and then get the mode of each of the feature and \n",
    "            # then add that as the feature of the centroid and then return the centroid.\n",
    "            for feature_column in cluster_data.columns:\n",
    "                mode = cluster_data[feature_column].mode()[0]\n",
    "                centroid.append(mode)\n",
    "            centroids.append(centroid)\n",
    "        return np.array(centroids)\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "        # this is basically doing the iterations to find the best fit and then stopping if the clusters don't change.\n",
    "        for _ in range(self.max_iter):\n",
    "            old_centroids = self.centroids.copy()\n",
    "            clusters = self.assign_clusters(data, self.centroids)\n",
    "            self.centroids = self.update_centroids(data, clusters)\n",
    "            if np.array_equal(old_centroids, self.centroids):\n",
    "                break\n",
    "        self.clusters = clusters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
