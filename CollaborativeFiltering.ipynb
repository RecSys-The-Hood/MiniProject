{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CollaborativeFiltering:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize CollaborativeFiltering object with user-item rating data.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing user-item ratings\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.similarity_matrix = None\n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \"\"\"\n",
    "        Calculate item-item similarity matrix based on user ratings.\n",
    "        \"\"\"\n",
    "        user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "        n_movies = user_item_matrix.shape[1]\n",
    "        similarity_matrix = np.zeros((n_movies, n_movies))\n",
    "        for i in range(n_movies):\n",
    "            for j in range(n_movies):\n",
    "                similarity_matrix[i, j] = np.dot(user_item_matrix.iloc[:, i], user_item_matrix.iloc[:, j]) / (np.linalg.norm(user_item_matrix.iloc[:, i]) * np.linalg.norm(user_item_matrix.iloc[:, j]) + 1e-9)\n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for items for a given user.\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id: ID of the user for whom to predict ratings\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame containing predicted ratings for each item\n",
    "        \"\"\"\n",
    "        user_ratings = self.train_data[self.train_data['UserID'] == user_id]\n",
    "        predicted_ratings = pd.DataFrame(index=self.similarity_matrix.index, columns=['PredictedRating'])\n",
    "        for item_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for _, rating_row in user_ratings.iterrows():\n",
    "                similarity = self.similarity_matrix.loc[item_id, rating_row['MovieID']]\n",
    "                numerator += similarity * rating_row['Rating']\n",
    "                denominator += similarity\n",
    "            predicted_ratings.loc[item_id, 'PredictedRating'] = numerator / (denominator + 1e-9)  # Add a small value to avoid division by zero\n",
    "        return predicted_ratings\n",
    "\n",
    "    def train_test_split(self, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Split the data into training and test sets.\n",
    "        \n",
    "        Parameters:\n",
    "        - test_size: Fraction of the data to be used for testing\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # for reproducibility\n",
    "        mask = np.random.rand(len(self.data)) < 1 - test_size\n",
    "        self.train_data = self.data[mask]\n",
    "        self.test_data = self.data[~mask]\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the Collaborative Filtering model on the test set.\n",
    "        \n",
    "        Returns:\n",
    "        - Mean squared error (MSE) of the predictions\n",
    "        \"\"\"\n",
    "        self.calculate_similarity_matrix()\n",
    "        mse_sum = 0\n",
    "        total_predictions = 0\n",
    "        for user_id in self.test_data['UserID'].unique():\n",
    "            user_test_ratings = self.test_data[self.test_data['UserID'] == user_id]\n",
    "            user_predicted_ratings = self.predict_ratings(user_id)\n",
    "            for _, row in user_test_ratings.iterrows():\n",
    "                if row['MovieID'] in user_predicted_ratings.index:\n",
    "                    total_predictions += 1\n",
    "                    mse_sum += (row['Rating'] - user_predicted_ratings.loc[row['MovieID'], 'PredictedRating']) ** 2\n",
    "        mse = mse_sum / total_predictions\n",
    "        return mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming 'data' is a pandas DataFrame with user-item ratings\n",
    "\n",
    "# Read data from CSV files\n",
    "users = pd.read_csv(\"users.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m cf\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m mse \u001b[38;5;241m=\u001b[39m cf\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse)\n",
      "Cell \u001b[1;32mIn[9], line 70\u001b[0m, in \u001b[0;36mCollaborativeFiltering.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Evaluate the Collaborative Filtering model on the test set.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    - Mean squared error (MSE) of the predictions\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_similarity_matrix()\n\u001b[0;32m     71\u001b[0m     mse_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     72\u001b[0m     total_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mCollaborativeFiltering.calculate_similarity_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_movies):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_movies):\n\u001b[1;32m---> 26\u001b[0m         similarity_matrix[i, j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(user_item_matrix\u001b[38;5;241m.\u001b[39miloc[:, i], user_item_matrix\u001b[38;5;241m.\u001b[39miloc[:, j]) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(user_item_matrix\u001b[38;5;241m.\u001b[39miloc[:, i]) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(user_item_matrix\u001b[38;5;241m.\u001b[39miloc[:, j]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-9\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_matrix \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(similarity_matrix, index\u001b[38;5;241m=\u001b[39muser_item_matrix\u001b[38;5;241m.\u001b[39mcolumns, columns\u001b[38;5;241m=\u001b[39muser_item_matrix\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kalya\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2511\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2509\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x_real\u001b[38;5;241m.\u001b[39mdot(x_real) \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2511\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdot(x)\n\u001b[0;32m   2512\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Merge dataframes\n",
    "data = pd.merge(pd.merge(users, ratings), movies)\n",
    "\n",
    "# Create CollaborativeFiltering instance\n",
    "cf = CollaborativeFiltering(data)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
