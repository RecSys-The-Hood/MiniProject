{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityMetric:\n",
    "\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarity(SimilarityMetric):\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v) + 1e-9)\n",
    "\n",
    "class PCCSimilarity(SimilarityMetric):\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        return self.__pearson_correlation(u, v)\n",
    "    \n",
    "    def __pearson_correlation(self, user1_ratings, user2_ratings):\n",
    "        common_items = user1_ratings.index.intersection(user2_ratings.index)\n",
    "        if len(common_items) < 2:  # Require at least 2 common items for correlation\n",
    "            return 0\n",
    "        user1_common_ratings = user1_ratings[common_items]\n",
    "        user2_common_ratings = user2_ratings[common_items]\n",
    "        correlation = user1_common_ratings.corr(user2_common_ratings)\n",
    "        if np.isnan(correlation):\n",
    "            return 0\n",
    "        return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        \"\"\"\n",
    "        Initialize CollaborativeFiltering object with user-item rating data.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing user-item ratings\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.similarity_matrix = None\n",
    "        self.metric = metric\n",
    "    \n",
    "    def calculate_similarity_matrix(self):\n",
    "        pass\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        pass\n",
    "\n",
    "    def train_test_split(self, test_size = 0.2):\n",
    "        \"\"\"\n",
    "        Split the data into training and test sets.\n",
    "        \n",
    "        Parameters:\n",
    "        - test_size: Fraction of the data to be used for testing\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # for reproducibility\n",
    "        mask = np.random.rand(len(self.data)) < 1 - test_size\n",
    "        self.train_data = self.data[mask]\n",
    "        self.test_data = self.data[~mask]\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringItemItem(CollaborativeFiltering):\n",
    "\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        super.__init__(data, metric)\n",
    "    \n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \n",
    "        user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "        n_movies = user_item_matrix.shape[1]\n",
    "        similarity_matrix = np.zeros((n_movies, n_movies))\n",
    "        for i in range(n_movies):\n",
    "            for j in range(n_movies):\n",
    "                similarity_matrix[i, j] = self.metric.calculateSimilarity(user_item_matrix.iloc[:, i], user_item_matrix.iloc[:, j])\n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for items for a given user.\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id: ID of the user for whom to predict ratings\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame containing predicted ratings for each item\n",
    "        \"\"\"\n",
    "        user_ratings = self.train_data[self.train_data['UserID'] == user_id]\n",
    "        predicted_ratings = pd.DataFrame(index=self.similarity_matrix.index, columns=['PredictedRating'])\n",
    "        for item_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for _, rating_row in user_ratings.iterrows():\n",
    "                similarity = self.similarity_matrix.loc[item_id, rating_row['MovieID']]\n",
    "                numerator += similarity * rating_row['Rating']\n",
    "                denominator += abs(similarity)\n",
    "            predicted_ratings.loc[item_id, 'PredictedRating'] = numerator / (denominator + 1e-9)  # Add a small value to avoid division by zero\n",
    "        return predicted_ratings\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the Collaborative Filtering model on the test set.\n",
    "        \n",
    "        Returns:\n",
    "        - Mean squared error (MSE) of the predictions\n",
    "        \"\"\"\n",
    "        self.calculate_similarity_matrix()\n",
    "        mse_sum = 0\n",
    "        total_predictions = 0\n",
    "        for user_id in self.test_data['UserID'].unique():\n",
    "            user_test_ratings = self.test_data[self.test_data['UserID'] == user_id]\n",
    "            user_predicted_ratings = self.predict_ratings(user_id)\n",
    "            for _, row in user_test_ratings.iterrows():\n",
    "                if row['MovieID'] in user_predicted_ratings.index:\n",
    "                    total_predictions += 1\n",
    "                    mse_sum += (row['Rating'] - user_predicted_ratings.loc[row['MovieID'], 'PredictedRating']) ** 2\n",
    "        mse = mse_sum / total_predictions\n",
    "        return mse\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringUserUser(CollaborativeFiltering):\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        \n",
    "        super.__init__(data, metric)\n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \n",
    "        user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "        n_users = user_item_matrix.shape[0]\n",
    "        similarity_matrix = np.zeros((n_users, n_users))\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_users):\n",
    "                similarity_matrix[i, j] = self.metric.calculateSimilarity(user_item_matrix.iloc[i, :], user_item_matrix.iloc[j, :])\n",
    "                \n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        user_ratings = self.train_data[self.train_data['UserID'] == user_id]\n",
    "        predicted_ratings = pd.DataFrame(index=self.similarity_matrix.index, columns=['PredictedRating'])\n",
    "        for other_user_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for _, rating_row in user_ratings.iterrows():\n",
    "                similarity = self.similarity_matrix.loc[user_id, other_user_id]\n",
    "                other_user_rating = self.train_data[(self.train_data['UserID'] == other_user_id) & (self.train_data['MovieID'] == rating_row['MovieID'])]['Rating']\n",
    "                if not other_user_rating.empty:\n",
    "                    numerator += similarity * float(other_user_rating)\n",
    "                    denominator += abs(similarity)\n",
    "            if denominator != 0:\n",
    "                predicted_ratings.loc[other_user_id, 'PredictedRating'] = numerator / denominator\n",
    "            else:\n",
    "                predicted_ratings.loc[other_user_id, 'PredictedRating'] = np.nan\n",
    "        return predicted_ratings\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.calculate_similarity_matrix()\n",
    "        mse_sum = 0\n",
    "        total_predictions = 0\n",
    "        for user_id in self.test_data['UserID'].unique():\n",
    "            user_test_ratings = self.test_data[self.test_data['UserID'] == user_id]\n",
    "            user_predicted_ratings = self.predict_ratings(user_id)\n",
    "            for _, row in user_test_ratings.iterrows():\n",
    "                other_user_rating = user_predicted_ratings.loc[row['UserID'], 'PredictedRating']\n",
    "                if not np.isnan(other_user_rating):\n",
    "                    total_predictions += 1\n",
    "                    mse_sum += (row['Rating'] - other_user_rating) ** 2\n",
    "        mse = mse_sum / total_predictions\n",
    "        return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"EncodedCombined.csv\")\n",
    "\n",
    "metric = CosineSimilarity()\n",
    "# Create CollaborativeFiltering instance\n",
    "cf = CollaborativeFilteringItemItem(data, metric)\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PCCSimilarity()\n",
    "cf = CollaborativeFilteringItemItem(data, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = CosineSimilarity()\n",
    "# Create CollaborativeFiltering instance\n",
    "cf = CollaborativeFilteringUserUser(data, metric)\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PCCSimilarity()\n",
    "cf = CollaborativeFilteringUserUser(data, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
