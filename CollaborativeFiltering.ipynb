{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityMetric:\n",
    "\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarity(SimilarityMetric):\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v) + 1e-9)\n",
    "\n",
    "class PCCSimilarity(SimilarityMetric):\n",
    "    def calculateSimilarity(self, u, v):\n",
    "        return self.__pearson_correlation(u, v)\n",
    "    \n",
    "    def __pearson_correlation(self, user1_ratings, user2_ratings):\n",
    "        common_items = user1_ratings.index.intersection(user2_ratings.index)\n",
    "        if len(common_items) < 2:  # Require at least 2 common items for correlation\n",
    "            return 0\n",
    "        user1_common_ratings = user1_ratings[common_items]\n",
    "        user2_common_ratings = user2_ratings[common_items]\n",
    "        correlation = user1_common_ratings.corr(user2_common_ratings)\n",
    "        if np.isnan(correlation):\n",
    "            return 0\n",
    "        return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        \"\"\"\n",
    "        Initialize CollaborativeFiltering object with user-item rating data.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing user-item ratings\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.similarity_matrix = None\n",
    "        self.metric = metric\n",
    "    \n",
    "    def calculate_similarity_matrix(self):\n",
    "        pass\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        pass\n",
    "\n",
    "    def train_test_split(self, test_size = 0.2):\n",
    "        \"\"\"\n",
    "        Split the data into training and test sets.\n",
    "        \n",
    "        Parameters:\n",
    "        - test_size: Fraction of the data to be used for testing\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # for reproducibility\n",
    "        mask = np.random.rand(len(self.data)) < 1 - test_size\n",
    "        self.train_data = self.data[mask]\n",
    "        self.test_data = self.data[~mask]\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the Collaborative Filtering model on the test set.\n",
    "\n",
    "        Returns:\n",
    "        - Mean squared error (MSE) of the predictions\n",
    "        \"\"\"\n",
    "\n",
    "        self.calculate_similarity_matrix()\n",
    "        mse_sum = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for user_id in self.test_data.index:\n",
    "            user_test_ratings = self.test_data.loc[user_id]\n",
    "            user_predicted_ratings = self.predict_ratings(user_id)\n",
    "            for movie_id, actual_rating in user_test_ratings.items():\n",
    "                predicted_rating = user_predicted_ratings.loc[movie_id, 'PredictedRating']\n",
    "                if not pd.isnull(predicted_rating):\n",
    "                    total_predictions += 1\n",
    "                    mse_sum += (actual_rating - predicted_rating) ** 2\n",
    "\n",
    "        mse = mse_sum / total_predictions\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringItemItem(CollaborativeFiltering):\n",
    "\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        super().__init__(data, metric)\n",
    "    \n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \n",
    "        # user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "        \n",
    "        n_movies = self.data.shape[1]\n",
    "        similarity_matrix = np.zeros((n_movies, n_movies))\n",
    "        for i in range(n_movies):\n",
    "            for j in range(n_movies):\n",
    "                similarity_matrix[i, j] = self.metric.calculateSimilarity(self.train_data.iloc[:, i], self.train_data.iloc[:, j])\n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=self.train_data.columns, columns=self.train_data.columns)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for items for a given user.\n",
    "\n",
    "        Parameters:\n",
    "        - user_id: ID of the user for whom to predict ratings\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame containing predicted ratings for each item\n",
    "        \"\"\"\n",
    "\n",
    "        user_ratings = self.data.loc[user_id]\n",
    "        predicted_ratings = pd.DataFrame(index=self.similarity_matrix.columns, columns=['PredictedRating'])\n",
    "\n",
    "        for movie_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for other_movie_id, similarity in self.similarity_matrix[movie_id].items():\n",
    "                other_movie_rating = user_ratings[other_movie_id]\n",
    "                if not pd.isnull(other_movie_rating):\n",
    "                    numerator += similarity * other_movie_rating\n",
    "                    denominator += abs(similarity)\n",
    "\n",
    "            \n",
    "            predicted_ratings.loc[movie_id, 'PredictedRating'] = numerator / (denominator + 1e-9)\n",
    "            \n",
    "\n",
    "        return predicted_ratings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilteringUserUser(CollaborativeFiltering):\n",
    "    def __init__(self, data, metric:SimilarityMetric):\n",
    "        \n",
    "        super().__init__(data, metric)\n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        \n",
    "        # user_item_matrix = self.train_data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "        n_users = self.data.shape[0]\n",
    "        similarity_matrix = np.zeros((n_users, n_users))\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_users):\n",
    "                similarity_matrix[i, j] = self.metric.calculateSimilarity(self.train_data.iloc[i, :], self.train_data.iloc[j, :])\n",
    "                \n",
    "        self.similarity_matrix = pd.DataFrame(similarity_matrix, index=self.train_data.index, columns=self.train_data.index)\n",
    "\n",
    "    def predict_ratings(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for items for a given user.\n",
    "\n",
    "        Parameters:\n",
    "        - user_id: ID of the user for whom to predict ratings\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame containing predicted ratings for each item\n",
    "        \"\"\"\n",
    "\n",
    "        predicted_ratings = pd.DataFrame(index=self.similarity_matrix.columns, columns=['PredictedRating'])\n",
    "\n",
    "        for movie_id in predicted_ratings.index:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for other_user_id, similarity in self.similarity_matrix[user_id].items():\n",
    "                other_user_rating = self.data.loc[other_user_id, movie_id]\n",
    "                if not pd.isnull(other_user_rating):\n",
    "                    numerator += similarity * other_user_rating\n",
    "                    denominator += abs(similarity)\n",
    "\n",
    "            predicted_ratings.loc[movie_id, 'PredictedRating'] = numerator / (denominator + 1e-9)\n",
    "            \n",
    "\n",
    "        return predicted_ratings\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14247/645754126.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv(\"EncodedCombined.csv\")\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"EncodedCombined.csv\")\n",
    "\n",
    "user_item_matrix = data.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "user_item_matrix_new = user_item_matrix.iloc[0:2000, 0:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.674702714551718\n"
     ]
    }
   ],
   "source": [
    "metric = CosineSimilarity()\n",
    "# Create CollaborativeFiltering instance\n",
    "cf = CollaborativeFilteringItemItem(user_item_matrix_new, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PCCSimilarity()\n",
    "cf = CollaborativeFilteringItemItem(user_item_matrix_new, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = CosineSimilarity()\n",
    "# Create CollaborativeFiltering instance\n",
    "cf = CollaborativeFilteringUserUser(user_item_matrix_new, metric)\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PCCSimilarity()\n",
    "cf = CollaborativeFilteringUserUser(user_item_matrix_new, metric)\n",
    "\n",
    "# Split data into train and test sets\n",
    "cf.train_test_split(test_size=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = cf.evaluate()\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
